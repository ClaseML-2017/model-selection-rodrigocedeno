{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random as rnd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regLinPoli2.csv\") ##insert your own path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.concat([rand_list, df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[[df.columns[-1]]], train_size=0.75)\n",
    "#print X_train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I recommend that after manipulating data using pandas and before modelling to convert dataframes into arrays. This may avoid some headaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train)\n",
    "X_test=np.asarray(X_test)\n",
    "Y_train=np.asarray(Y_train)\n",
    "Y_test=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure for data standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This procedure is useful for classroom examples. For a real implementation you have to have a separete method \n",
    "# for transforming the production data so you can transform it as you get it with the fitted scaler\n",
    "## The procedure returns a standardized copy of the input data\n",
    "def normalize(X_train,X_test,Y_train,Y_test,do=True):\n",
    "\n",
    "    scale_X=preprocessing.StandardScaler()\n",
    "    scale_y=preprocessing.StandardScaler()\n",
    "    \n",
    "    train_X=np.copy(X_train)\n",
    "    train_y=np.copy(Y_train)\n",
    "    test_X=np.copy(X_test)\n",
    "    test_y=np.copy(Y_test)\n",
    "    if do:\n",
    "        scale_X.fit(train_X)\n",
    "        scale_y.fit(train_y)\n",
    "        train_X=scale_X.transform(train_X)\n",
    "        train_y=scale_y.transform(train_y)\n",
    "        test_X=scale_X.transform(test_X)\n",
    "        test_y=scale_y.transform(test_y)\n",
    "    return train_X,test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental regularized regression procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Transfer function\n",
    "def salida(w,X):\n",
    "    return X.dot(w[1:]) +w[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training function\n",
    "def entrena(X,y,w,la=0.0,eta=0.01):\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        error=y[i]-salida(w,X[i])\n",
    "        w[0]=w[0]+eta*(error)\n",
    "        w[1:]=w[1:]+eta*(error*X[i])-la*w[1:]\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcError(X,y,w,w0):\n",
    "    return np.mean((X.dot(w)+w0-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X,test_X,train_y,test_y=normalize(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w=np.asarray([rnd.random() for i in range(1+len(train_X[0]))])\n",
    "for i in range(100):\n",
    "    w=entrena(train_X,train_y,w,la=0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.32866731e-01,   8.01385175e-01,  -1.59955472e-01,\n",
       "         4.54698212e-01,   4.96854188e-01,  -1.22208008e-02,\n",
       "         3.18332916e-01,   8.50688918e-01,   4.65150391e-01,\n",
       "         5.42568684e-01,   1.36960029e-01,   1.17324321e-01,\n",
       "        -4.80001362e-02,   7.70212422e-03,   8.48405852e-02,\n",
       "        -2.54769310e-02,   6.20170116e-02,  -2.47577420e-02,\n",
       "         3.96171879e-02,  -6.13357566e-02,  -1.23355201e-01,\n",
       "         1.42851892e-02,  -7.81925902e-02,  -1.45863330e-01,\n",
       "        -2.86996850e-02,  -2.79304437e-02,   7.25170911e-02,\n",
       "        -1.99799595e-02,  -1.08183575e-02,  -3.29038252e-02,\n",
       "         1.51879769e-02,   4.62537502e-02,  -3.30947725e-02,\n",
       "         7.00845625e-04,  -1.00666164e-01,   3.07621964e-02,\n",
       "        -7.33265416e-02,  -1.35586400e-01,   3.29201547e-02])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545525704555\n",
      "0.612329117539\n"
     ]
    }
   ],
   "source": [
    "## flatten here to convert y from a matrix to a vector. Only 1 response variable\n",
    "print calcError(train_X,train_y.flatten(),w[1:],w[0])\n",
    "print calcError(test_X,test_y.flatten(),w[1:],w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame(train_X)\n",
    "train_Y = pd.DataFrame(train_y)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat = pd.concat([train_X, train_Y], axis = 1)\n",
    "concat_names = range(39)\n",
    "concat.columns = [concat_names]\n",
    "#concat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_list = pd.DataFrame([[rnd.randint(1, 6)] for iter_num in range(len(concat))])\n",
    "cross_table = pd.concat([rand_list, concat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_names = range(40)\n",
    "cross_table.columns = [cross_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.204044614381\n",
      "0.182751623799\n",
      "0.173378329918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "train_X_1 = []\n",
    "train_Y_1 = []\n",
    "val_X_1 = []\n",
    "val_Y_1 = []\n",
    "err1_2 = 0\n",
    "err2_2 = 0\n",
    "lambdas = np.array([-0.002,0.0015,0.01])\n",
    "w=np.asarray([rnd.random() for i in range(38)])\n",
    "for j in lambdas:\n",
    "    for i in range(1, 7):\n",
    "        train_1 = cross_table[cross_table[0] != i]\n",
    "        val_1 = cross_table[cross_table[0] == i]\n",
    "        train_1 = (train_1.drop([0], axis=1))\n",
    "        val_1 = (val_1.drop([0], axis=1))\n",
    "        train_X_1 = np.asarray(train_1[train_1.columns[1:-1]])\n",
    "        train_Y_1 = np.asarray(train_1[[train_1.columns[-1]]])\n",
    "        val_X_1 = np.asarray(val_1[val_1.columns[1:-1]])\n",
    "        val_Y_1 = np.asarray(val_1[[val_1.columns[-1]]])\n",
    "        entrena(train_X_1,train_Y_1,w,j,eta=0.01)\n",
    "        err1 = calcError(train_X_1,train_Y_1.flatten(),w[1:],w[0])\n",
    "        err2 = calcError(val_X_1,val_Y_1.flatten(),w[1:],w[0])\n",
    "    err1_2 = err1 / 6\n",
    "    err2_2 = err2 / 6\n",
    "    print err1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
